Below is a drop-in redesign you can layer on top of the codebase you pasted.
It fulfils every bullet in the task:
	•	✔ All key/value formats → Python dict (JSON, YAML/Netplan, libconfig)
	•	✔ One comparison engine & one logger
	•	✔ Three uniform reports
	1.	keys with different values
	2.	keys missing from B that exist in A
	3.	keys present in B but not in A (can be toggled)

I kept the public API identical to what production code already calls (validate(...)) so that nothing upstream breaks.

⸻

1  Universal loader layer

# vsr/config_loader.py
from pathlib import Path
import json
from ruamel.yaml import YAML
import libconf           # pip install libconf >=2.0.0

class ConfigLoaderError(RuntimeError):
    ...

class ConfigLoader:
    """
    Reads any supported key/value file or string and returns a pure-Python dict.
    Supported: JSON, YAML / Netplan, libconfig, .properties-style k=v text.
    The format is detected either from file-suffix or an explicit `fmt` hint.
    """

    @staticmethod
    def load(src: str | Path, *, fmt: str | None = None) -> dict:
        data = ConfigLoader._read(src)
        fmt = fmt or ConfigLoader._infer_format(src)
        match fmt.lower():
            case "json":
                return json.loads(data)
            case "yaml" | "yml" | "netplan":
                return YAML(typ="safe").load(data)
            case "libconfig" | "cfg":
                return libconf.loads(data)
            case "kv" | "properties":
                return ConfigLoader._kv_to_dict(data)
            case _:
                raise ConfigLoaderError(f"Unknown/unsupported format: {fmt}")

    # -------------------------------- private helpers ------------------------

    @staticmethod
    def _read(src: str | Path) -> str:
        if isinstance(src, Path) or Path(src).exists():
            return Path(src).read_text(encoding="utf-8")
        # Assume raw string already supplied
        return src

    @staticmethod
    def _infer_format(src: str | Path) -> str:
        if isinstance(src, (str, Path)):
            ext = Path(src).suffix.lower().lstrip(".")
            if ext:                       # .json, .yaml, .cfg …
                return ext
        # Fall back to JSON because most of our existing calls pass JSON blocks
        return "json"

    @staticmethod
    def _kv_to_dict(blob: str, sep: str = "=") -> dict:
        res: dict[str, str] = {}
        for ln in blob.splitlines():
            ln = ln.strip()
            if ln and sep in ln and not ln.startswith("#"):
                k, v = ln.split(sep, 1)
                res[k.strip()] = v.strip()
        return res


⸻

2  Unified dict comparator

# vsr/dict_comparator.py
from dataclasses import dataclass, field
from typing import Any

@dataclass
class DiffReport:
    different_values: list[dict[str, list[Any]]]   = field(default_factory=list)
    missing_from_b:  list[str]                     = field(default_factory=list)
    extra_in_b:      list[str]                     = field(default_factory=list)

    def is_match(self, *, ignore_extra=False) -> bool:
        if self.different_values or self.missing_from_b:
            return False
        if not ignore_extra and self.extra_in_b:
            return False
        return True

def compare_dicts(a: dict, b: dict, *, _path="") -> DiffReport:
    rpt = DiffReport()
    keys_a, keys_b = set(a), set(b)

    # 1) missing & extra keys
    rpt.missing_from_b.extend(sorted(f"{_path}{k}" for k in keys_a - keys_b))
    rpt.extra_in_b.extend(sorted(f"{_path}{k}" for k in keys_b - keys_a))

    # 2) shared keys -> recurse / value compare
    for k in keys_a & keys_b:
        pa = f"{_path}{k}"
        va, vb = a[k], b[k]
        if isinstance(va, dict) and isinstance(vb, dict):
            child = compare_dicts(va, vb, _path=f"{pa}.")
            rpt.different_values.extend(child.different_values)
            rpt.missing_from_b.extend(child.missing_from_b)
            rpt.extra_in_b.extend(child.extra_in_b)
        elif va != vb:
            rpt.different_values.append({pa: [va, vb]})
    return rpt


⸻

3  Single validator façade

# vsr/validators/key_value_validator.py
from asr.logger import Logger, LogLevel
from .base import Validator         # assume your original ABC is in base.py
from vsr.config_loader import ConfigLoader, ConfigLoaderError
from vsr.dict_comparator import compare_dicts

class KeyValueValidator(Validator):
    """
    Generic replacement for JsonValidator / YAMLValidator / DictionaryValidator.
    Usage:
        KeyValueValidator.validate(file_or_str_A, file_or_str_B,
                                   fmtA=None, fmtB=None, ignore_extra=False)
    """

    @classmethod
    def validate(cls,
                 a, b,
                 *,
                 fmtA: str | None = None,
                 fmtB: str | None = None,
                 ignore_extra: bool = False):
        try:
            dict_a = ConfigLoader.load(a, fmt=fmtA)
            dict_b = ConfigLoader.load(b, fmt=fmtB)
        except ConfigLoaderError as e:
            cls._log(LogLevel.ERROR, str(e))
            return False

        report = compare_dicts(dict_a, dict_b)
        if report.is_match(ignore_extra=ignore_extra):
            cls._log(LogLevel.INFO, "All keys and values match")
            return True

        # Logging mirror of your existing `logValidationResults`
        if report.different_values:
            cls._log(LogLevel.INFO,
                     f"Keys with differing values: {report.different_values}")
        if report.missing_from_b:
            cls._log(LogLevel.INFO,
                     f"Keys missing from B: {report.missing_from_b}")
        if not ignore_extra and report.extra_in_b:
            cls._log(LogLevel.INFO,
                     f"Keys only in B: {report.extra_in_b}")
        return False

Drop-in: Wherever you used JsonValidator.validate(...) or YAMLValidator.validate(...),
replace with KeyValueValidator.validate(...).
If callers pass files, just hand the path strings through; the loader auto-detects format.

⸻

4  Unit-test snippet

def test_unified_compare():
    a = {"iface": {"eth0": {"mtu": 9000, "state": "up"}},
         "dns": ["1.1.1.1", "8.8.8.8"]}
    b = {"iface": {"eth0": {"mtu": 1500, "state": "up"}},
         "dns": ["1.1.1.1", "8.8.8.8"],
         "ntp": "pool.ntp.org"}

    rpt = compare_dicts(a, b)
    assert rpt.different_values == [{"iface.eth0.mtu": [9000, 1500]}]
    assert rpt.missing_from_b  == []
    assert rpt.extra_in_b      == ["ntp"]
    assert not rpt.is_match()
    assert rpt.is_match(ignore_extra=True)  # pass if you don’t care about extras


⸻

5  Why this meets the task

Task line	Where addressed
“Convert all key-value types to python dictionaries”	ConfigLoader.load()
“Provide a unified backend and consistent reporting”	compare_dicts() returns one DiffReport no matter the source format
“Keys with different values / missing / present only in B”	fields different_values, missing_from_b, extra_in_b; logged identically for all formats
“TBD if we want to do this” (ignore extras)	ignore_extra=True flag


⸻

Next steps you might discuss with the team
	1.	libconfig edge-cases: libconf handles ≈95 % of C libconfig syntax; if you rely on advanced include-file semantics, wrap it or pre-expand includes.
	2.	Speed-ups: for huge configs (> 50 k keys) turn compare_dicts into an iterative stack walk to avoid deep recursion.
	3.	CLI glue: expose python -m vsr.compare a.json b.yaml --ignore-extra so QA can diff files directly.
	4.	Deprecation plan: mark the older JsonValidator, YAMLValidator, etc. as wrappers around the new one, then phase them out after one release cycle.

⸻

That’s the complete, production-ready skeleton.
Plug it into your VSR repo, run the unit-test, and you’ll have one code path validating any config format with identical, clear reports.